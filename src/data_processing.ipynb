{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: c:\\Users\\MOS\\Koen\\Wondherkenning\\Wound-Classification-DL\\src\\..\\data\\balanced\n",
      "Directory already exists: c:\\Users\\MOS\\Koen\\Wondherkenning\\Wound-Classification-DL\\src\\..\\data\\train\n",
      "Directory already exists: c:\\Users\\MOS\\Koen\\Wondherkenning\\Wound-Classification-DL\\src\\..\\data\\val\n",
      "Directory already exists: c:\\Users\\MOS\\Koen\\Wondherkenning\\Wound-Classification-DL\\src\\..\\data\\processed\n",
      "Directory already exists: c:\\Users\\MOS\\Koen\\Wondherkenning\\Wound-Classification-DL\\src\\..\\data\\balanced\n",
      "Directory already exists: c:\\Users\\MOS\\Koen\\Wondherkenning\\Wound-Classification-DL\\src\\..\\data\\processed\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "\n",
    "# Define the base directory relative to the notebook's location\n",
    "base_dir = os.getcwd()  # Gets the current working directory\n",
    "data_dir = os.path.join(base_dir, '..', 'data')\n",
    "\n",
    "# Update paths to be relative\n",
    "balanced_dir = os.path.join(data_dir, 'balanced')\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'val')\n",
    "input_dir = os.path.join(data_dir, 'processed')\n",
    "output_dir = os.path.join(data_dir, 'balanced')\n",
    "dataset_path = os.path.join(data_dir, 'Categorized Wound Images Dataset')\n",
    "processed_dir = os.path.join(data_dir, 'processed')\n",
    "\n",
    "# Ensure directories exist\n",
    "for directory in [balanced_dir, train_dir, val_dir, input_dir, output_dir, processed_dir]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f'Directory created: {directory}')\n",
    "    else:\n",
    "        print(f'Directory already exists: {directory}')\n",
    "\n",
    "# Update the rest of the code to use these relative paths\n",
    "# Example usage:\n",
    "# balance_dataset(input_dir, output_dir, target_size)\n",
    "# split_data(balanced_dir, train_dir, val_dir, split_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: c:\\Users\\MOS\\Koen\\Wondherkenning\\Wound-Classification-DL\\src\\..\\data\\processed\n"
     ]
    }
   ],
   "source": [
    "# processed_dir = r'E:\\Projects\\Wound-Classification-DL\\data\\processed'\n",
    "\n",
    "\n",
    "if not os.path.exists(processed_dir):\n",
    "    os.makedirs(processed_dir)\n",
    "    print(f'Directory created: {processed_dir}')\n",
    "else:\n",
    "    print(f'Directory already exists: {processed_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (128, 128)\n",
    "\n",
    "# dataset_path = r'E:\\Projects\\Wound-Classification-DL\\data\\Categorized Wound Images Dataset'\n",
    "folders = [folder for folder in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, folder))]\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(dataset_path, folder)\n",
    "    output_folder = os.path.join(processed_dir, folder)\n",
    "    \n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for file in os.listdir(folder_path):\n",
    "        input_path = os.path.join(folder_path, file)\n",
    "        output_path = os.path.join(output_folder, file)\n",
    "        \n",
    "        try:\n",
    "            with Image.open(input_path) as img:\n",
    "                resized_img = img.resize(target_size)\n",
    "                resized_img.save(output_path)\n",
    "        except Exception as e:\n",
    "            print(f'Error processing {input_path}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "def augment_image(img):\n",
    "    transformations = [\n",
    "        lambda x: cv2.rotate(x, cv2.ROTATE_90_CLOCKWISE),\n",
    "        lambda x: cv2.flip(x, 1),\n",
    "        lambda x: cv2.GaussianBlur(x, (5, 5), 0),\n",
    "        lambda x: shift_image(x, shift_x=10, shift_y=10),\n",
    "    ]\n",
    "    transform = random.choice(transformations)\n",
    "    augmented = transform(img)\n",
    "    if len(augmented.shape) == 3 and augmented.shape[2] == 3:\n",
    "        return augmented\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def shift_image(img, shift_x, shift_y):\n",
    "    rows, cols, _ = img.shape\n",
    "    M = np.float32([[1, 0, shift_x], [0, 1, shift_y]])\n",
    "    shifted = cv2.warpAffine(img, M, (cols, rows), borderMode=cv2.BORDER_REFLECT_101)\n",
    "    return shifted\n",
    "\n",
    "def balance_dataset(input_dir, output_dir, target_size):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for folder in tqdm(os.listdir(input_dir)):\n",
    "        folder_path = os.path.join(input_dir, folder)\n",
    "        output_folder = os.path.join(output_dir, folder)\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "        \n",
    "        images = os.listdir(folder_path)\n",
    "        \n",
    "        for img in images:\n",
    "            input_path = os.path.join(folder_path, img)\n",
    "            output_path = os.path.join(output_folder, img)\n",
    "            image = cv2.imread(input_path)\n",
    "            cv2.imwrite(output_path, image)\n",
    "        \n",
    "        while len(os.listdir(output_folder)) < target_size:\n",
    "            img = random.choice(images)\n",
    "            input_path = os.path.join(folder_path, img)\n",
    "            image = cv2.imread(input_path)\n",
    "            augmented_image = augment_image(image)\n",
    "            output_path = os.path.join(output_folder, f'aug_{random.randint(10000, 99999)}.jpg')\n",
    "            cv2.imwrite(output_path, augmented_image)\n",
    "\n",
    "# input_dir = r'E:\\Projects\\Wound-Classification-DL\\data\\processed'\n",
    "# output_dir = r'E:\\Projects\\Wound-Classification-DL\\data\\balanced'\n",
    "target_size = 1000\n",
    "\n",
    "balance_dataset(input_dir, output_dir, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folders: 100%|██████████| 10/10 [00:58<00:00,  5.81s/it]\n"
     ]
    }
   ],
   "source": [
    "def split_data(source_dir, train_dir, val_dir, split_ratio=0.8):\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.makedirs(train_dir)\n",
    "    if not os.path.exists(val_dir):\n",
    "        os.makedirs(val_dir)\n",
    "    \n",
    "    for folder in tqdm(os.listdir(source_dir), desc='Processing Folders'):\n",
    "        folder_path = os.path.join(source_dir, folder)\n",
    "        train_folder = os.path.join(train_dir, folder)\n",
    "        val_folder = os.path.join(val_dir, folder)\n",
    "        \n",
    "        if not os.path.exists(train_folder):\n",
    "            os.makedirs(train_folder)\n",
    "        if not os.path.exists(val_folder):\n",
    "            os.makedirs(val_folder)\n",
    "        \n",
    "        files = os.listdir(folder_path)\n",
    "        np.random.shuffle(files)\n",
    "        \n",
    "        split_index = int(len(files) * split_ratio)\n",
    "        train_files = files[:split_index]\n",
    "        val_files = files[split_index:]\n",
    "        \n",
    "        for file in train_files:\n",
    "            input_path = os.path.join(folder_path, file)\n",
    "            output_path = os.path.join(train_folder, file)\n",
    "            process_and_save_image(input_path, output_path)\n",
    "        \n",
    "        for file in val_files:\n",
    "            input_path = os.path.join(folder_path, file)\n",
    "            output_path = os.path.join(val_folder, file)\n",
    "            process_and_save_image(input_path, output_path)\n",
    "\n",
    "def process_and_save_image(input_path, output_path):\n",
    "    try:\n",
    "        with Image.open(input_path) as img:\n",
    "            rgb_image = img.convert('RGB')\n",
    "            rgb_image.save(output_path)\n",
    "    except Exception as e:\n",
    "        print(f'Error processing file {input_path}: {e}')\n",
    "\n",
    "# balanced_dir = r'E:\\Projects\\Wound-Classification-DL\\data\\balanced'\n",
    "# train_dir = r'E:\\Projects\\Wound-Classification-DL\\data\\train'\n",
    "# val_dir = r'E:\\Projects\\Wound-Classification-DL\\data\\val'\n",
    "\n",
    "split_data(balanced_dir, train_dir, val_dir, split_ratio=0.8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
